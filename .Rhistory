testing_error = mean((ridge.pred-quality[-train])^2)
quad_error[k,]=testing_error
}
mean(quad_error) # Error is 0.004176, which improve significantly compare to LS-ridge regression
library(glmnet)
?cv.glmnet
?glmer
install.packages("quantmod")
install.packages("PerformanceAnalytics")
##################### Global Rotation Alogrithm #####################
## Credit to Frank Grossmann at logical-invest.com
## His article about this strategy can be found:
## http://seekingalpha.com/article/1622832-a-global-market-rotation-strategy-with-an-annual-performance-of-41_4-percent-since-2003
## Developed for educational demostration by Anthony Lei
######## Library & Initialize Parametors ########
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
rm(list=ls())
######## Library & Initialize Parametors ########
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
######## Download Stock Price ########
sectorSymbols <- c("MDY", "FEZ", "EEM", "ILF", "EPP", "EDV", "SHY")
getSymbols(sectorSymbols ,from="1990-01-01")
getSymbols("SPY")
for (i in 1 : length(sectorSymbols)) {
adjClosed[[i]] <- Ad(get(sectorSymbols[[i]]))
}
adjClosed <- do.call(cbind, adjClosed)
######## Calculate Daily Returns ########
dailyReturns <- na.omit(Return.calculate(adjClosed))
SPYReturns <- na.omit(Return.calculate(Ad(SPY)))
######## Determine portfolio weighting by ranking securities ########
Returns <- ROC(adjClosed, n = 90, type = "discrete")
tail(dailyReturn)
?tail
dailyReturns <- na.omit(Return.calculate(adjClosed))
SPYReturns <- na.omit(Return.calculate(Ad(SPY)))
tail(dailyReturns)
Returns <- ROC(adjClosed, n = 90, type = "discrete")
Returns <- Returns[complete.cases(Returns),]
for (i in 1: length(index(Returns))){
ranking[[i]] <- rank(as.data.frame(-Returns[i,1:length(Returns[1,])]),
ties.method = "max")}
tail(ranking)
dailyReturns <- na.omit(Return.calculate(adjClosed))
SPYReturns <- na.omit(Return.calculate(Ad(SPY)))
######## Determine portfolio weighting by ranking securities ########
Returns <- ROC(adjClosed, n = 90, type = "discrete")
Returns <- Returns[complete.cases(Returns),]
for (i in 1: length(index(Returns))){
ranking[[i]] <- rank(as.data.frame(-Returns[i,1:length(Returns[1,])]),
ties.method = "max")}
ranking <- as.xts(do.call(rbind, ranking), order.by = index(Returns))
tail(ranking)
weighting <- weighting[endpoints(weighting, on="months"),]
weighting <- xts(((t(apply(ranking, 1, function(data) {return(data <=1)}))) * 1),
order.by = index(ranking))
weighting <- weighting[endpoints(weighting, on="months"),]
tail(weighting)
######## Calculates Strategy Returns ########
strategyReturns <- Return.portfolio(R = dailyReturns, weights = weighting)
tail(strategyReturns)
sum(tail(strategyReturns))
sum(strategyReturns)
######## Evaluates Performance ########
strategyReturns <- merge(strategyReturns, SPYReturns, join='inner')
charts.PerformanceSummary(strategyReturns)
tail(dailyReturns)
tail(getSymbols)
getSymbols
strategyReturns <- Return.portfolio(R = dailyReturns, weights = weighting)
######## Evaluates Performance ########
strategyReturns <- merge(strategyReturns, SPYReturns, join='inner')
charts.PerformanceSummary(strategyReturns)
rbind(table.AnnualizedReturns(strategyReturns),
SortinoRatio(strategyReturns),
maxDrawdown(strategyReturns),
CalmarRatio(strategyReturns))
apply.yearly(strategyReturns, Return.cumulative)
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
######## Download Stock Price ########
sectorSymbols <- c("MDY", "FEZ", "EEM", "ILF", "EPP", "EDV", "SHY")
getSymbols(sectorSymbols ,from="1990-01-01")
getSymbols("SPY")
for (i in 1 : length(sectorSymbols)) {
adjClosed[[i]] <- Ad(get(sectorSymbols[[i]]))
}
adjClosed <- do.call(cbind, adjClosed)
######## Calculate Daily Returns ########
dailyReturns <- na.omit(Return.calculate(adjClosed))
SPYReturns <- na.omit(Return.calculate(Ad(SPY)))
######## Determine portfolio weighting by ranking securities ########
Returns <- ROC(adjClosed, n = 90, type = "discrete")
Returns <- Returns[complete.cases(Returns),]
for (i in 1: length(index(Returns))){
ranking[[i]] <- rank(as.data.frame(-Returns[i,1:length(Returns[1,])]),
ties.method = "max")}
ranking <- as.xts(do.call(rbind, ranking), order.by = index(Returns))
weighting <- xts(((t(apply(ranking, 1, function(data) {return(data <=1)}))) * 1),
order.by = index(ranking))
weighting <- weighting[endpoints(weighting, on="months"),]
######## Calculates Strategy Returns ########
strategyReturns <- Return.portfolio(R = dailyReturns, weights = weighting)
strategyReturns <- merge(strategyReturns, SPYReturns, join='inner')
charts.PerformanceSummary(strategyReturns)
rbind(table.AnnualizedReturns(strategyReturns),
SortinoRatio(strategyReturns),
maxDrawdown(strategyReturns),
CalmarRatio(strategyReturns))
apply.yearly(strategyReturns, Return.cumulative)
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
######## Download Stock Price ########
sectorSymbols <- c("MDY", "FEZ", "EEM", "ILF", "EPP", "EDV", "SHY")
getSymbols(sectorSymbols ,from="1990-01-01")
getSymbols("SPY")
adjclosed
dailyReturns
tail(dailyReturns)
tail(getsymbols)
rm(list=())
rm(list=ls())
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
######## Download Stock Price ########
sectorSymbols <- c("MDY", "FEZ", "EEM", "ILF", "EPP", "EDV", "SHY")
getSymbols(sectorSymbols ,from="1990-01-01")
getSymbols("SPY")
tail(EDV)
tial(SPY)
tail(SPY)
require(PerformanceAnalytics)
require(quantmod)
adjClosed <- ranking <- weighting <- list()
######## Download Stock Price ########
sectorSymbols <- c("MDY", "FEZ", "EEM", "ILF", "EPP", "EDV", "SHY")
getSymbols(sectorSymbols ,from="1990-01-01")
tail(EDV)
rm(list = ls())
write.table(averages_data, "averages_data.txt",row.name = FALSE)
library((plyr))
library(plyr)
# Step 1
# Merge the Traning and test sets to create one data set
x_train  = read.table("train/X_train.txt")
library(plyr)
x_train  = read.table("train/X_train.txt")
y_train  = read.table("train/y_train.txt")
subject_train = read.table("train/subject_train.txt")
library(plyr)
x_train  = read.table("train/X_train.txt")
rm(list=ls())
x_train  = read.table("train/X_train.txt")
y_train  = read.table("train/y_train.txt")
x_train = read.table("X_train")
ls
getwd
getwd()
getwd()
setwd("C:/Users/YuBo/Dropbox/Data_Science/Getting_and_Reading_data")
rm(list=ls())
library(plyr)
x_train  = read.table("train/X_train.txt")
x_train = read.table("X_train.txt")
x_train.train
x_train = read.table("train/X_train.txt")
rm(list=ls())
x_train  = read.table("X_train.txt")
y_train  = read.table("y_train.txt")
subject_train = read.table("subject_train.txt")
x_test = read.table("X_test.txt")
y_test = read.table("y_test.txt")
subject_test = read.table("subject_test.txt")
x_data = rbind(x_train,x_test)
y_dta = rbind(y_train,y_test)
#creat 'subject' data set
subject_data = rbind(subject_train,subject_test)
feature = read.table("features.txt")
mean_and_std_features = grep("-(mean\std)\\(\\)",features[, 2]))
mean_and_std_features = grep("-(mean|std)\\(\\)",features[, 2]))
mean_and_std_features = grep("-(mean|std)\\(\\)",features[, 2])
features = read.table("features.txt")
View(feature)
features = read.table("features.txt")
mean_and_std_features = grep("-(mean|std)\\(\\)",features[, 2])
x_data = x_data[, mean_and_std_features]
names(x_data) = features[mean_and_std_features,2]
activities = read.table("activity_labels.txt")
y_data[, 1] = activities[y_data[,1],2]
View(activities)
activities = read.table("activity_labels.txt")
y_data[, 1] = activities[y_data[,1],2]
y_data[, 1] = activities[y_data[, 1],2]
y_data[, 1]
y_data = rbind(y_train,y_test)
y_data[, 1] = activities[y_data[, 1],2]
names(y_data) = "activity"
names(subject_data) = "subject"
all_data = cbind(x_data,y_data,subject_data)
averages_data = ddply(all_data,.(subject,activity), function(x) colMeans(x[, 1:66]))
write.table(averages_data, "averages_data.txt",row.name = FALSE)
rm(list=ls())
library(plyr)
rm(list=ls())
library(plyr)
# Step 1
# Merge the Traning and test sets to create one data set
x_train  = read.table("X_train.txt")
y_train  = read.table("y_train.txt")
subject_train = read.table("subject_train.txt")
x_test = read.table("X_test.txt")
y_test = read.table("y_test.txt")
subject_test = read.table("subject_test.txt")
# create 'X' data set
x_data = rbind(x_train,x_test)
# creat 'y' data set
y_data = rbind(y_train,y_test)
#creat 'subject' data set
subject_data = rbind(subject_train,subject_test)
# Step 2
# Extract onlyy the measurements on the mean and stdr deviation for each measurement
features = read.table("features.txt")
# get only columns with mean() or stad() in their names
mean_and_std_features = grep("-(mean|std)\\(\\)",features[, 2])
# subset the desired columns
x_data = x_data[, mean_and_std_features]
# correct the columns names
names(x_data) = features[mean_and_std_features,2]
# Step 3
# Use descriptive activity names to name the activities in the data set
activities = read.table("activity_labels.txt")
# update values with correct activity names
y_data[, 1] = activities[y_data[, 1],2]
# correct column name
names(y_data) = "activity"
# Step 4
# Appropiately label the data set with descriptive variable names
names(subject_data) = "subject"
# bind all the data in signle dtaa set
all_data = cbind(x_data,y_data,subject_data)
# Step 5
# cearte a second, independet tidy data set with the average of each variable
# for each acticiry and each subject
# 66 <- 68 colums but last two (acticiry & subject)
averages_data = ddply(all_data,.(subject,activity), function(x) colMeans(x[, 1:66]))
write.table(averages_data, "averages_data.txt",row.name = FALSE)
rm(list=ls())
datalocation = "./household_power_consumption.txt"
data = read.table(datalocation,header = TRUE, sep = ";",stringsAsFactors = FALSE, dec = ".")
getwd()
setwd("C:/Users/YuBo/Dropbox/Data_Science/Exploratory_Data_Analysis")
datalocation = "./household_power_consumption.txt"
data = read.table(datalocation,header = TRUE, sep = ";",stringsAsFactors = FALSE, dec = ".")
subsetdata = data[data$Date %in% c("1/2/2007","2/2/2007") ,]
datatime = strptime(paste(subsetdata$Date, subsetdata$Time, sep = " "),"%d/%m/%Y %H:%M:%S")
gap = as.numeric(subsetdata$Global_active_power)
png("plot2.png",width=480,height=480)
plot(datatime,gap,type = "l",xlab="",ylab = "Global Active Power (kw)")
dev.off()
rm(list=ls())
setwd("C:/Users/YuBo/Dropbox/Data_Science/Exploratory_Data_Analysis")
rm(list=ls())
setwd("C:/Users/YuBo/Dropbox/Data_Science/Exploratory_Data_Analysis")
datalocation = "./household_power_consumption.txt"
data = read.table(datalocation,header = TRUE, sep = ";",stringsAsFactors = FALSE, dec = ".")
subsetdata = data[data$Date %in% c("1/2/2007","2/2/2007") ,]
datatime = strptime(paste(subsetdata$Date, subsetdata$Time,sep = " "),"%d/%m/%Y %H:%M:%S")
gap = as.numeric(subsetdata$Global_active_power)
submetering1 = as.numeric(subsetdata$Sub_metering_1)
submetering2 = as.numeric(subsetdata$Sub_metering_2)
submetering3 = as.numeric(subsetdata$Sub_metering_3)
png("plot3.png",width = 480,height = 480)
plot(datatime,submeterting1,type = "1", ylab = "Energy Submetering", xlab = "")
plot(datatime,submetering1,type = "1", ylab = "Energy Submetering", xlab = "")
plot(datatime,submetering1,type = "l", ylab = "Energy Submetering", xlab = "")
lines(datatime,submetering2,type = "l",col = "red")
lines(datatime,submetering3,type = "l", col = "blue")
legend("topright",c("Sub_metering1","Sub_meterting2","Sub_metering3"),lty = 1, lwd = 2.5, col=c("black","red","blue"))
dev.off()
subsetdata = data[data$Date %in% c("1/2/2007","2/2/2007") ,]
datatime = strptime(paste(subsetdata$Date, subsetdata$Time,sep = " "),"%d/%m/%Y %H:%M:%S")
gap = as.numeric(subsetdata$Global_active_power)
voltage = as.numeric(subsetdata$Voltage)
submetering1 = as.numeric(subsetdata$Sub_metering_1)
submetering2 = as.numeric(subsetdata$Sub_metering_2)
submetering3 = as.numeric(subsetdata$Sub_metering_3)
png("plot4.png",width = 480, height = 480)
par(mfrow = c(2,2))
plot(datatime, gap, type = "l", xlab = "", ylab = "Global Acitve Power",cex = 0.2)
plot(datatime,voltage, typt = "l",xlab = "datatime",ylab = "Voltage")
plot(datatime,submetering1,type = "l",ylab = "Energy Submetering", xlab = "")
plot(datatime, gap, type = "l", xlab = "", ylab = "Global Acitve Power",cex = 0.2)
plot(datatime,voltage, typt = "l",xlab = "datatime",ylab = "Voltage")
plot(datatime,voltage, type = "l",xlab = "datatime",ylab = "Voltage")
plot(datatime,submetering1,type = "l",ylab = "Energy Submetering", xlab = "")
lines(datatime, submetering2,type = "l",col = "red")
lines(datatime, submetering3,type = "l",col = "blue")
legend("topright",c("Sub_metering1","Sub_meterting2","Sub_metering3"),lty = 1, lwd = 2.5, col=c("black","red","blue"),bty = "o")
plot(datatime,gap,type = "l", xlab = "datatime", ylab = "Global Active Power")
dev.off()
getwd()
setwd("C:/Users/YuBo/Dropbox/Data_Science/Getting_and_Reading_data")
rm(list=ls())
library(plyr)
# Step 1
# Merge the Traning and test sets to create one data set
x_train  = read.table("X_train.txt")
y_train  = read.table("y_train.txt")
subject_train = read.table("subject_train.txt")
x_test = read.table("X_test.txt")
y_test = read.table("y_test.txt")
subject_test = read.table("subject_test.txt")
# create 'X' data set
x_data = rbind(x_train,x_test)
# creat 'y' data set
y_data = rbind(y_train,y_test)
#creat 'subject' data set
subject_data = rbind(subject_train,subject_test)
# Step 2
# Extract onlyy the measurements on the mean and stdr deviation for each measurement
features = read.table("features.txt")
# get only columns with mean() or stad() in their names
mean_and_std_features = grep("-(mean|std)\\(\\)",features[, 2])
# subset the desired columns
x_data = x_data[, mean_and_std_features]
# correct the columns names
names(x_data) = features[mean_and_std_features,2]
# Step 3
# Use descriptive activity names to name the activities in the data set
activities = read.table("activity_labels.txt")
# update values with correct activity names
y_data[, 1] = activities[y_data[, 1],2]
# correct column name
names(y_data) = "activity"
# Step 4
# Appropiately label the data set with descriptive variable names
names(subject_data) = "subject"
# bind all the data in signle dtaa set
all_data = cbind(x_data,y_data,subject_data)
# Step 5
# cearte a second, independet tidy data set with the average of each variable
# for each acticiry and each subject
# 66 <- 68 colums but last two (acticiry & subject)
averages_data = ddply(all_data,.(subject,activity), function(x) colMeans(x[, 1:66]))
#write.table(averages_data, "averages_data.txt",row.name = FALSE)
write.table(averages_data, "tidy.txt",row.name = FALSE)
rm(list = ls())
getwd()
setwd("C:/Users/YuBo/Dropbox/Data_Science/Explortary_Date_Analysis/Project2")
setwd("C:/Users/YuBo/Dropbox/Data_Science/Explortary_Data_Analysis/Project2")
setwd("C:/Users/YuBo/Dropbox/Data_Science/Explortory_Data_Analysis/Project2")
setwd("C:/Users/YuBo/Dropbox/Data_Science/Exploratory_Data_Analysis/Project2")
nei = readRDS("summarySCC_PM25.rds")
scc = readRDS("Source_Classification_Code.rds")
baltimorenei  = NEI[NEI$fips == "24510",]
rm(list = ls())
setwd("C:/Users/YuBo/Dropbox/Data_Science/Exploratory_Data_Analysis/Project2")
# Load data
NEI = readRDS("summarySCC_PM25.rds")
SCC = readRDS("Source_Classification_Code.rds")
baltimorenei  = NEI[NEI$fips == "24510",]
aggtotalB = aggregate(Emission ~ year, baltimoreNEI, sum)
baltimoreNei  = NEI[NEI$fips == "24510",]
baltimoreNEI  = NEI[NEI$fips == "24510",]
aggtotalB = aggregate(Emission ~ year, baltimoreNEI, sum)
aggtotalB = aggregate(Emissions ~ year, baltimoreNEI, sum)
png("plot2.png",width = 480, height = 480, units = "px" bg = "transparent")
png("plot2.png",width = 480, height = 480, units = "px", bg = "transparent")
barplot(
aggtotalB$Emissions,
names.arg = aggtotalB$year,
xlab = "Year",
ylab = "PM2.5 Emissions (Tons)",
main = "Total PM2.5 Emissions From all Baltimore City Sources"
)
dev.off
dev.off()
rm(list = ls())
setwd("C:/Users/YuBo/Dropbox/Data_Science/Exploratory_Data_Analysis/Project2")
rm(list = ls())
setwd("C:/Users/YuBo/Dropbox/Data_Science/Exploratory_Data_Analysis/Project2")
# Load data
NEI = readRDS("summarySCC_PM25.rds")
SCC = readRDS("Source_Classification_Code.rds")
baltimoreNEI = NEI[NEI$fips = "24510",]
aggtotalbal = aggregate (Emissions ~ year, baltimoreNEI, sum)
baltimoreNEI = NEI[NEI$fips = "24510",]
baltimoreNEI = NEI[NEI$fips == "24510",]
aggtotalbal = aggregate (Emissions ~ year, baltimoreNEI, sum)
png("plot3.png",width = 480, height = 480, units = "px", bg = "transparent")
library(ggplot2)
ggp = ggplot(baltimoreNEI, aes(factor(year),Emissions, fill = type)) +
geom_bar(stat = "identity") +
theme_bw() + guides(fill = FALSE) +
facet_grid(.~type,scales = "free", space = "free" ) +
labs(x="year", y = expression("Total PM"[2.5]*" Emission (Tons)"))+
labs(title = expression("PM"[2.5]*" Emissions, Baltimore City 1999-2008 by Source Type"))
print(ggp)
dev.off()
View(SCC)
rm(list = ls())
setwd("C:/Users/YuBo/Dropbox/Data_Science/Exploratory_Data_Analysis/Project2")
# Load data
NEI = readRDS("summarySCC_PM25.rds")
SCC = readRDS("Source_Classification_Code.rds")
combustionR = grepl("comb",SCC$SCC.Level.One,ignore.case = TRUE)
coalR = grepl("coal", SCC$SCC.Level.Four, ignore.case = TRUE)
coalC = (combutionR & coalR)
coalC = (combustionR & coalR)
combutionSCC = SCC[coalC,]$SCC
combutionNEI = NEI[NEI$SCC %in% combutionSCC,]
png("plot4.png",width = 480, height = 480, units = "px", bg = "transparent")
library(ggplot2)
ggp = ggplot(combustionNEI, aes(factor(year),Emission/10^5)) +
geom_bar(stat = "identity", fill = "grey", width = 0.75) +
theme_bw() + guides(fill = FALSE) +
labs(x = "year", y = expression("Total PM"[2.5]*" Emission (10^5 Tons)")) +
labs(title = expression("PM"[2.5]*" Coal Combustion Source Emissions Across US from 1999-2008"))
combustionNEI = NEI[NEI$SCC %in% combutionSCC,]
png("plot4.png",width = 480, height = 480, units = "px", bg = "transparent")
library(ggplot2)
ggp = ggplot(combustionNEI, aes(factor(year),Emission/10^5)) +
geom_bar(stat = "identity", fill = "grey", width = 0.75) +
theme_bw() + guides(fill = FALSE) +
labs(x = "year", y = expression("Total PM"[2.5]*" Emission (10^5 Tons)")) +
labs(title = expression("PM"[2.5]*" Coal Combustion Source Emissions Across US from 1999-2008"))
print(ggp)
dev.off
ggp = ggplot(combustionNEI, aes(factor(year),Emissions/10^5)) +
geom_bar(stat = "identity", fill = "grey", width = 0.75) +
theme_bw() + guides(fill = FALSE) +
labs(x = "year", y = expression("Total PM"[2.5]*" Emission (10^5 Tons)")) +
labs(title = expression("PM"[2.5]*" Coal Combustion Source Emissions Across US from 1999-2008"))
print(ggp)
dev.off
dev.off()
rm(list = ls())
setwd("C:/Users/YuBo/Dropbox/Data_Science/Exploratory_Data_Analysis/Project2")
# Load data
NEI = readRDS("summarySCC_PM25.rds")
SCC = readRDS("Source_Classification_Code.rds")
# Subset Coal  combustion related NEI data
combustionR = grepl("comb",SCC$SCC.Level.One,ignore.case = TRUE)
coalR = grepl("coal", SCC$SCC.Level.Four, ignore.case = TRUE)
coalC = (combustionR & coalR)
combutionSCC = SCC[coalC,]$SCC
combustionNEI = NEI[NEI$SCC %in% combutionSCC,]
png("plot4.png",width = 480, height = 480, units = "px", bg = "transparent")
library(ggplot2)
ggp = ggplot(combustionNEI, aes(factor(year),Emissions/10^5)) +
geom_bar(stat = "identity", fill = "grey", width = 0.75) +
theme_bw() + guides(fill = FALSE) +
labs(x = "year", y = expression("Total PM"[2.5]*" Emission (10^5 Tons)")) +
labs(title = expression("PM"[2.5]*" Coal Combustion Source Emissions Across US from 1999-2008"))
print(ggp)
dev.off()
rm(list = ls())
setwd("C:/Users/YuBo/Dropbox/Data_Science/Exploratory_Data_Analysis/Project2")
# Load data
NEI = readRDS("summarySCC_PM25.rds")
SCC = readRDS("Source_Classification_Code.rds")
# Subset Coal  combustion related NEI data
combustionR = grepl("comb",SCC$SCC.Level.One,ignore.case = TRUE)
coalR = grepl("coal", SCC$SCC.Level.Four, ignore.case = TRUE)
coalC = (combustionR & coalR)
combutionSCC = SCC[coalC,]$SCC
combustionNEI = NEI[NEI$SCC %in% combutionSCC,]
png("plot4.png",width = 480, height = 480, units = "px", bg = "transparent")
library(ggplot2)
ggp = ggplot(combustionNEI, aes(factor(year),Emissions/10^5)) +
geom_bar(stat = "identity", fill = "grey", width = 0.75) +
theme_bw() + guides(fill = FALSE) +
labs(x = "year", y = expression("Total PM"[2.5]*" Emission (10^5 Tons)")) +
labs(title = expression("PM"[2.5]*" Coal Combustion Source Emissions Across US from 1999-2008"))
print(ggp)
dev.off()
combustionR = grepl("comb",SCC$SCC.Level.One,ignore.case = TRUE)
coalR = grepl("coal", SCC$SCC.Level.Four, ignore.case = TRUE)
coalC = (combustionR & coalR)
combutionSCC = SCC[coalC,]$SCC
combustionNEI = NEI[NEI$SCC %in% combutionSCC,]
png("plot4.png",width = 480, height = 480, units = "px", bg = "transparent")
library(ggplot2)
ggp = ggplot(combustionNEI, aes(factor(year),Emissions/10^5)) +
geom_bar(stat = "identity", fill = "grey", width = 0.75) +
theme_bw() + guides(fill = FALSE) +
labs(x = "year", y = expression("Total PM"[2.5]*" Emission (10^5 Tons)")) +
labs(title = expression("PM"[2.5]*" Coal Combustion Source Emissions Across US from 1999-2008"))
print(ggp)
dev.off()
combustionRelated <- grepl("comb", SCC$SCC.Level.One, ignore.case=TRUE)
coalRelated <- grepl("coal", SCC$SCC.Level.Four, ignore.case=TRUE)
coalCombustion <- (combustionRelated & coalRelated)
combustionSCC <- SCC[coalCombustion,]$SCC
combustionNEI <- NEI[NEI$SCC %in% combustionSCC,]
png("plot4.png",width=480,height=480,units="px",bg="transparent")
library(ggplot2)
ggp <- ggplot(combustionNEI,aes(factor(year),Emissions/10^5)) +
geom_bar(stat="identity",fill="grey",width=0.75) +
theme_bw() +  guides(fill=FALSE) +
labs(x="year", y=expression("Total PM"[2.5]*" Emission (10^5 Tons)")) +
labs(title=expression("PM"[2.5]*" Coal Combustion Source Emissions Across US from 1999-2008"))
print(ggp)
dev.off()
rm(list = ls())
